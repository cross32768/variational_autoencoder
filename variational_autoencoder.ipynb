{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 0.4.1\n",
      "torchvision version: 0.2.1\n",
      "Is GPU available: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('torchvision version:', torchvision.__version__)\n",
    "print('Is GPU available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# デバイスとハイパーパラメータ\n",
    "\n",
    "# デバイスの準備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "# バッチサイズの指定\n",
    "batchsize = 128\n",
    "\n",
    "# 回すエポック数の指定\n",
    "n_epochs = 100\n",
    "\n",
    "# 学習率の指定\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# 乱数シードの指定\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "# VAEの潜在空間の次元数の指定\n",
    "embed_dim = 10\n",
    "\n",
    "# 画像を保存するディレクトリ名の指定\n",
    "output_dir = './VAE_' + str(embed_dim)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training data: 60000\n",
      "The number of test data: 10000\n"
     ]
    }
   ],
   "source": [
    "# データセットの準備\n",
    "\n",
    "# Tensorにして、-1～1の範囲に正規化\n",
    "tf = transforms.Compose([transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# 今回はMNISTを使用\n",
    "mnist_train = datasets.MNIST(root = '../data', train = True, transform = tf, download = True)\n",
    "mnist_test = datasets.MNIST(root = '../data', train = False, transform = tf, download = False)\n",
    "\n",
    "# データローダーを容易\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size = batchsize, shuffle = True, num_workers = 4)\n",
    "mnist_test_loader = DataLoader(mnist_test, batch_size = batchsize, shuffle = False, num_workers = 4)\n",
    "\n",
    "print('The number of training data:', len(mnist_train))\n",
    "print('The number of test data:', len(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAEのencoderを定義\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_out):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(1,  32, kernel_size = 5, stride = 2, padding = 2)\n",
    "        self.cv2 = nn.Conv2d(32, 64, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.fc3 = nn.Linear(64*7*7, 256)\n",
    "        self.fc4_mean = nn.Linear(256, n_out)\n",
    "        self.fc4_logvar = nn.Linear(256, n_out)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.cv1(x)\n",
    "        h = self.bn1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        \n",
    "        h = self.cv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        \n",
    "        h = h.view(h.size(0), -1)\n",
    "        \n",
    "        h = self.fc3(h)\n",
    "        h = self.bn3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        \n",
    "        out_mean = self.fc4_mean(h)\n",
    "        out_logvar = self.fc4_logvar(h)\n",
    "        return out_mean, out_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAEのdecoderを定義\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, 256)\n",
    "        self.fc2 = nn.Linear(256, 64*7*7)\n",
    "        self.tc3 = nn.ConvTranspose2d(64, 32, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.tc4 = nn.ConvTranspose2d(32, 1, kernel_size =  4, stride = 2, padding = 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(64*7*7)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.fc1(x)\n",
    "        h = self.bn1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "\n",
    "        h = self.fc2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        \n",
    "        h = h.view(h.size(0), 64, 7, 7)\n",
    "        \n",
    "        h = self.tc3(h)\n",
    "        h = self.bn3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        \n",
    "        out = self.tc4(h)\n",
    "        out = torch.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoderとdecoderをまとめ、reparametrization trick等を合わせてまとめてVAEを構成\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, n_emb):\n",
    "        super(VAE, self).__init__()\n",
    "        self.n_emb = n_emb\n",
    "        self.encoder = Encoder(n_emb)\n",
    "        self.decoder = Decoder(n_emb)\n",
    "        \n",
    "    def embed(self, x):\n",
    "        out_mean, out_logvar = self.encoder(x)\n",
    "        return out_mean, out_logvar\n",
    "    \n",
    "    def sample(self, n_sample):\n",
    "        z = torch.randn(n_sample. self.n_emb)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_mean, out_logvar = self.embed(x)\n",
    "        eps = torch.randn(out_mean.size())\n",
    "        z = (0.5 * out_logvar).exp() * eps + out_mean\n",
    "        out = self.decoder(z)\n",
    "        return out, out_mean, out_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trainable parameters: 1691509\n",
      "\n",
      "Model:\n",
      " VAE(\n",
      "  (encoder): Encoder(\n",
      "    (cv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (cv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (fc3): Linear(in_features=3136, out_features=256, bias=True)\n",
      "    (fc4_mean): Linear(in_features=256, out_features=10, bias=True)\n",
      "    (fc4_logvar): Linear(in_features=256, out_features=10, bias=True)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
      "    (fc2): Linear(in_features=256, out_features=3136, bias=True)\n",
      "    (tc3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (tc4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(3136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer:\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0.0005\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ネットワークを実体化、オプティマイザを定義\n",
    "net = VAE(embed_dim)\n",
    "net = net.to(device) # CPU/GPUにモデルを送信\n",
    "\n",
    "# オプティマイザは取り敢えずAdam, 学習率は上で指定、weight_decayを適当にかける\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate, weight_decay = 0.0005)\n",
    "\n",
    "# モデルのtarinableな(勾配を要求する)パラメータの数をカウントする（.numel()で要素数の合計がわかる）\n",
    "num_trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "# モデルの構造、オプティマイザの表示\n",
    "print('The number of trainable parameters:', num_trainable_params)\n",
    "print('\\nModel:\\n', net)\n",
    "print('\\nOptimizer:\\n', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAEのロス関数を定義\n",
    "def loss_VAE(recon_x, x, out_mean, out_logvar):\n",
    "    recon_err = F.mse_loss(recon_x, x)\n",
    "    kldiv_err = -0.5 * torch.sum(1 + out_logvar - out_mean.pow(2) - out_logvar.exp())\n",
    "    final_err = recon_err + kldiv_err\n",
    "    \n",
    "    return final_err, recon_err, kldiv_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# １エポック分の学習を行う関数\n",
    "def train(train_loader):\n",
    "    net.train() # モデルを学習モードにする\n",
    "    running_final_loss = 0\n",
    "    running_recon_loss = 0\n",
    "    running_kldiv_loss = 0\n",
    "    \n",
    "    for inputs, _ in train_loader:\n",
    "        inputs =  inputs.to(device) # モデルとTensorを同じインタフェースでCPU/GPU転送できる \n",
    "        recon_inputs, out_mean, out_logvar = net(inputs)\n",
    "        final_loss, recon_loss, kldiv_loss = loss_VAE(recon_inputs, inputs, out_mean, out_logvar)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_final_loss += final_loss.item() # .item()でスカラ値を単要素Tensorから取り出す\n",
    "        running_recon_loss += recon_loss.item()\n",
    "        running_kldiv_loss += kldiv_loss.item()\n",
    "        \n",
    "    final_loss = running_final_loss / len(train_loader.dataset)\n",
    "    recon_loss = running_recon_loss / len(train_loader.dataset)\n",
    "    kldiv_loss = running_kldiv_loss / len(train_loader.dataset)\n",
    "\n",
    "    return final_loss, recon_loss, kldiv_loss # 戻り値は訓練誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ポック分のテスト（実質バリデーションだが）を行う関数\n",
    "def test(test_loader, epoch):\n",
    "    net.eval() # モデルを学習モードにする\n",
    "    running_final_loss = 0\n",
    "    running_recon_loss = 0\n",
    "    running_kldiv_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs =  inputs.to(device) # モデルとTensorを同じインタフェースでCPU/GPU転送できる \n",
    "            recon_inputs, out_mean, out_logvar = net(inputs)\n",
    "            final_loss, recon_loss, kldiv_loss = loss_VAE(recon_inputs, inputs, out_mean, out_logvar)\n",
    "        \n",
    "            running_final_loss += final_loss.item() # .item()でスカラ値を単要素Tensorから取り出す\n",
    "            running_recon_loss += recon_loss.item()\n",
    "            running_kldiv_loss += kldiv_loss.item()\n",
    "        \n",
    "    final_loss = running_final_loss / len(test_loader.dataset)\n",
    "    recon_loss = running_recon_loss / len(test_loader.dataset)\n",
    "    kldiv_loss = running_kldiv_loss / len(test_loader.dataset)\n",
    "    \n",
    "    # 10エポックごとに最後のミニバッチの生成画像を保存する\n",
    "    if epoch % 5 == 0:\n",
    "        n_save_image = 8        \n",
    "        comparison = torch.cat([inputs[:n_save_image], recon_inputs[:n_save_image]])\n",
    "        save_image(comparison.data.cpu(),'{}/reconstruction_{}.png'.format(output_dir, epoch), nrow=n_save_image)\n",
    "        \n",
    "    return final_loss, recon_loss, kldiv_loss # 戻り値はテスト（バリデーション）誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/5] train_loss:0.0043 test_loss:0.0043\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-291-5d4d8190e986>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_loss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_final_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_recon_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_kldiv_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_train_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtest_final_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_recon_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_kldiv_loss\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_test_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-285-74f722928ea9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# モデルとTensorを同じインタフェースでCPU/GPU転送できる\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mrecon_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_logvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mfinal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkldiv_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_VAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_logvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-282-7767e8ed0431>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mout_logvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0meps\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mout_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_logvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-281-f20c66986ec3>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習の実行と、モデルの保存（学習ログは.npyで、モデル状態は.pthで　←　モデル状態の保存は他にもいろいろある？）\n",
    "train_loss_list = [[],[],[]]\n",
    "test_loss_list = [[],[],[]]\n",
    "for epoch in range(n_epochs):\n",
    "    train_final_loss, train_recon_loss, train_kldiv_loss = train(mnist_train_loader)\n",
    "    test_final_loss, test_recon_loss, test_kldiv_loss  = test(mnist_test_loader, epoch)\n",
    "    \n",
    "    train_loss_list[0].append(train_final_loss)\n",
    "    train_loss_list[1].append(train_recon_loss)\n",
    "    train_loss_list[2].append(train_kldiv_loss)\n",
    "\n",
    "    test_loss_list[0].append(test_final_loss)\n",
    "    test_loss_list[1].append(test_recon_loss)\n",
    "    test_loss_list[2].append(test_kldiv_loss)\n",
    "\n",
    "    print('epoch[%d/%d] train_loss:%1.4f test_loss:%1.4f' % \\\n",
    "                                (epoch+1, n_epochs, train_final_loss, test_final_loss))\n",
    "\n",
    "\n",
    "np.save(output_dir + 'train_loss_list.npy', np.array(train_loss_list))\n",
    "np.save(output_dir + 'validation_loss_list.npy', np.array(test_loss_list))\n",
    "\n",
    "torch.save(net.state_dict(), output_dir + 'VAE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
